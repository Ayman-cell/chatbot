# ğŸ¤– Assistant IA Multilingue - Cerebras Llama 3.1-8B

**Un chatbot intelligent et multilingue basÃ© sur l'IA gÃ©nÃ©rative avec rÃ©cupÃ©ration de documents (RAG) avancÃ©e**

ğŸš€ **[Essayer l'application en ligne](https://chatbot-aymaan.streamlit.app/)**

---

## ğŸ“‹ Vue d'ensemble

Ce projet est un **assistant IA conversationnel complet** construit avec Streamlit et le modÃ¨le **Cerebras Llama 3.1-8B**. C'est une application web interactive qui combine les capacitÃ©s de traitement du langage naturel (NLP) avec un systÃ¨me avancÃ© de rÃ©cupÃ©ration et de gÃ©nÃ©ration augmentÃ©e par rÃ©cupÃ©ration (RAG) pour fournir des rÃ©ponses prÃ©cises et contextuelles.

---

## âœ¨ FonctionnalitÃ©s principales

### 1. **Chatbot Conversationnel Multilingue**
- ğŸŒ Support complet de **plusieurs langues** (FranÃ§ais, Anglais, Espagnol, Allemand, etc.)
- ğŸ’¬ Conversations naturelles et fluides avec l'IA
- ğŸ§  ComprÃ©hension contextuelle avancÃ©e
- ğŸ“ Historique des conversations sauvegardÃ© automatiquement en **JSON**
- ğŸ”„ Gestion des tours de parole (user â†” assistant)

### 2. **SystÃ¨me RAG (Retrieval-Augmented Generation) AvancÃ©**
- ğŸ“„ **Support multi-formats** : PDF, Excel, DOCX, TXT
- ğŸ§© **Chunking intelligent** : Adaptation automatique de la taille des chunks selon le type de contenu :
  - **Contenu mathÃ©matique** : 960 caractÃ¨res (optimisÃ© pour les formules)
  - **Contenu orientÃ© code** : 720 caractÃ¨res (optimisÃ© pour la syntaxe)
  - **Contenu gÃ©nÃ©raliste** : 1200 caractÃ¨res (optimisÃ© pour les textes normaux)
- ğŸ” **Recherche sÃ©mantique amÃ©liorÃ©e** via embeddings FAISS
- ğŸ“Š **Re-ranking intelligent** des rÃ©sultats avec cross-encoder
- ğŸ¯ RÃ©cupÃ©ration des **documents les plus pertinents** pour chaque question

### 3. **Gestion AvancÃ©e des Tokens Cerebras**
- â±ï¸ **Limitation des requÃªtes** en temps rÃ©el :
  - 30 requÃªtes par minute
  - 64,000 tokens par minute
  - 900 requÃªtes par heure
  - 1,000,000 tokens par jour
- ğŸ“Š **Affichage des statistiques d'usage** en direct
- â³ **Gestion automatique des files d'attente** quand les limites sont atteintes
- ğŸ”„ **Retry automatique** avec dÃ©lai (max 3 tentatives)

### 4. **Interface Web Intuitive (Streamlit)**
- ğŸ¨ **Design moderne et responsive**
- ğŸ“± **Layout adaptatif** (widest mode pour une meilleure utilisation de l'espace)
- ğŸ¯ **Panneau latÃ©ral** avec options et configurations
- ğŸ“ˆ **Affichage des statistiques** en temps rÃ©el
- ğŸ›ï¸ **ContrÃ´les interactifs** pour ajuster les paramÃ¨tres

### 5. **Gestion des Fichiers Utilisateur**
- ğŸ“¤ **Upload multi-fichiers** avec validation
- ğŸ—‚ï¸ **Traitement automatique** de documents volumineux
- ğŸ’¾ **Extraction intelligente** du contenu textuel
- ğŸ“Š **Gestion efficace** de la mÃ©moire pour les gros fichiers

### 6. **Sauvegarde et Historique des Conversations**
- ğŸ’¾ **Sauvegarde JSON automatique** de chaque conversation
- ğŸ” **Identifiants uniques** (UUID) pour chaque conversation
- â° **MÃ©tadonnÃ©es temporelles** (date/heure)
- ğŸ“‹ **Chargement et visualisation** des conversations prÃ©cÃ©dentes
- ğŸ”„ **Reprise de conversations** anciennes

### 7. **Analyse et Traitements AvancÃ©s**
- ğŸ“ˆ **Statistiques linguistiques** sur les messages
- ğŸ§® **Compteur de tokens** pour optimiser l'utilisation
- ğŸ“Š **Analyse de la similaritÃ©** entre requÃªtes avec TF-IDF et cosine similarity
- ğŸ”¬ **Extraction d'informations** via expressions rÃ©guliÃ¨res avancÃ©es

### 8. **Optimisation des Performances**
- âš¡ **Cache Streamlit** pour accÃ©lÃ©rer le re-rendering
- ğŸ” **Gestion sÃ©curisÃ©e** des API keys
- ğŸ“¦ **Chunking optimisÃ©** selon le type de document
- ğŸ¯ **Retrieval de documents** efficace avec FAISS
- ğŸ”„ **DÃ©lai entre requÃªtes** configurable

---

## ğŸ› ï¸ Technologies utilisÃ©es

| Technologie | Utilisation |
|---|---|
| **Streamlit** | Framework web pour l'interface utilisateur |
| **Cerebras Llama 3.1-8B** | ModÃ¨le LLM pour la gÃ©nÃ©ration de texte |
| **LangChain** | Orchestration des chaÃ®nes d'IA et RAG |
| **FAISS** | Vector store pour la recherche sÃ©mantique |
| **HuggingFace Embeddings** | CrÃ©ation d'embeddings textuels |
| **Sentence Transformers** | Cross-encoder pour le re-ranking |
| **PyPDF** | Lecture de fichiers PDF |
| **OpenPyXL** | Traitement de fichiers Excel |
| **Pandas** | Manipulation de donnÃ©es |
| **Scikit-learn** | TF-IDF et analyse de similaritÃ© |
| **NumPy** | Calculs numÃ©riques et vectoriels |

---

## ğŸ“‹ PrÃ©requis

Avant de dÃ©marrer, assurez-vous d'avoir :
- Python 3.9 ou supÃ©rieur
- pip (gestionnaire de paquets Python)
- Une API key Cerebras (gratuite et facile Ã  obtenir)
- Au moins 4GB de RAM
- Une connexion Internet stable

---

## ğŸš€ Installation et dÃ©marrage

### 1. **Cloner le dÃ©pÃ´t**
```bash
git clone https://github.com/yourusername/Ayman-cell-chatbot.git
cd Ayman-cell-chatbot
```

### 2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
```

**Activation de l'environnement :**
- **Windows** :
  ```bash
  .\venv\Scripts\activate
  ```
- **macOS/Linux** :
  ```bash
  source venv/bin/activate
  ```

### 3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

### 4. **Configurer l'API Cerebras**
Ouvrez le fichier `llama.py` et remplacez la clÃ© API :
```python
CEREBRAS_API_KEY = "votre-clÃ©-api-ici"
```

ou dÃ©finissez la variable d'environnement :
```bash
set CEREBRAS_API_KEY=votre-clÃ©-api-ici  # Windows
export CEREBRAS_API_KEY=votre-clÃ©-api-ici  # macOS/Linux
```

### 5. **Lancer l'application**
```bash
streamlit run llama.py
```

L'application s'ouvrira automatiquement sur `http://localhost:8501`

---

## ğŸ“– Guide d'utilisation

### Interface de Chat
1. **Entrez votre question** dans le champ de texte en bas
2. **Appuyez sur EntrÃ©e** ou cliquez sur le bouton d'envoi
3. **L'IA traite** et rÃ©pond en temps rÃ©el
4. **Votre conversation est sauvegardÃ©e** automatiquement

### Utiliser le RAG (upload de documents)

1. **Cliquez sur "Upload des fichiers"** dans la barre latÃ©rale
2. **SÃ©lectionnez des fichiers** (PDF, Excel, DOCX, TXT)
3. **L'application traite** les documents automatiquement
4. **Vos questions** bÃ©nÃ©ficieront du contexte des documents
5. **Les rÃ©ponses** seront plus prÃ©cises et documentÃ©es

### Types de documents supportÃ©s

| Format | Extension | Support |
|---|---|---|
| PDF | .pdf | âœ… Complet |
| Excel | .xlsx, .xls | âœ… Complet |
| Word | .docx | âœ… Complet |
| Texte | .txt | âœ… Complet |

### Visualiser l'historique

1. **Consultez le panneau latÃ©ral** pour voir vos conversations passÃ©es
2. **Cliquez sur une conversation** pour la recharger
3. **Continuez ou rÃ©visez** votre historique

---

## âš™ï¸ Configuration avancÃ©e

### ParamÃ¨tres RAG

Vous pouvez ajuster les paramÃ¨tres de RAG dans la section `RAG_CONFIG` :

```python
RAG_CONFIG = {
    "general": {
        "chunk_size": 1200,        # Taille des chunks en caractÃ¨res
        "chunk_overlap": 300,      # Chevauchement entre chunks
        "separators": ["\n\n", "\n", " ", ""]
    },
    "math_heavy": {
        "chunk_size": 960,
        "chunk_overlap": 225,
        "separators": ["\n\n", "\n$$", "\n$", " ", ""]
    },
    "code_heavy": {
        "chunk_size": 720,
        "chunk_overlap": 150,
        "separators": ["\n\n", "\n\`\`\`", "\nclass", "\ndef", " "]
    }
}
```

### Limites des tokens Cerebras

Modifiez `TOKEN_LIMITS` pour ajuster les restrictions :

```python
TOKEN_LIMITS = {
    "max_requests_per_minute": 30,
    "max_tokens_per_minute": 64000,
    "max_requests_per_hour": 900,
    "max_tokens_per_hour": 1000000,
    "max_requests_per_day": 14400,
    "max_tokens_per_day": 1000000,
    "max_tokens_per_request": 8000,
    "chunk_size": 4000,
    "delay_between_requests": 2,
    "max_retries": 3
}
```

---

## ğŸ“ Structure du projet

```
Ayman-cell-chatbot/
â”œâ”€â”€ llama.py                    # Fichier principal de l'application
â”œâ”€â”€ conversations/              # Dossier de stockage des conversations JSON
â”‚   â”œâ”€â”€ conv_*.json            # Fichiers de conversation sauvegardÃ©s
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ README.md                   # Ce fichier
â””â”€â”€ .gitignore                 # Fichiers Ã  ignorer dans Git
```

### Fichier de conversation (JSON)

```json
{
  "id": "unique-uuid",
  "timestamp": "2024-02-13T10:30:45.123456",
  "messages": [
    {
      "role": "user",
      "content": "Votre question",
      "timestamp": "2024-02-13T10:30:45.123456"
    },
    {
      "role": "assistant",
      "content": "RÃ©ponse de l'IA",
      "timestamp": "2024-02-13T10:30:50.456789"
    }
  ]
}
```

---

## ğŸ”’ SÃ©curitÃ© et bonnes pratiques

### âš ï¸ Points importants

1. **API Keys** : Ne commitez JAMAIS votre clÃ© API
   - Utilisez un fichier `.env` pour les clÃ©s secrÃ¨tes
   - Utilisez `python-dotenv` pour charger les variables d'environnement

2. **DonnÃ©es sensibles** : 
   - Les conversations sont stockÃ©es localement
   - Aucune donnÃ©e sensible n'est envoyÃ©e Ã  des tiers non autorisÃ©s

3. **Limites de l'API** :
   - Respectez les quotas Cerebras
   - L'application gÃ¨re automatiquement les dÃ©passements

---

## ğŸ› DÃ©pannage

### ProblÃ¨me : "ClÃ© API invalide"
```
Solution : VÃ©rifiez que votre CEREBRAS_API_KEY est correctement dÃ©finie
```

### ProblÃ¨me : "FAISS not found"
```bash
pip install faiss-cpu
# ou pour GPU :
pip install faiss-gpu
```

### ProblÃ¨me : Conversations non sauvegardÃ©es
```
Solution : VÃ©rifiez que le dossier 'conversations' existe et que vous avez les permissions d'Ã©criture
```

### ProblÃ¨me : Lenteur de l'application
```
Solution : 
- RÃ©duisez la taille des chunks (chunk_size)
- Diminuez le nombre de documents traitÃ©s
- Videz le cache de Streamlit : streamlit cache clear
```

---

## ğŸ“Š Cas d'usage

### 1. **Support client intelligent**
Fournissez vos documents de support et le chatbot rÃ©pond aux questions des clients de maniÃ¨re automatique.

### 2. **Assistant de recherche**
Uploadez des papers de recherche ou des livres et posez des questions spÃ©cifiques.

### 3. **Tuteur personnel**
Inutile d'expliquer des concepts - l'IA peut vous aider avec des documents fournis.

### 4. **Analyse de documents**
Traitez plusieurs documents et obtenez des rÃ©sumÃ©s ou analyses comparatives.

### 5. **Assistance multilingue**
Demandez Ã  l'IA de rÃ©pondre dans diffÃ©rentes langues, mÃªme si vos documents sont dans une autre langue.

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Pour contribuer :

1. **Fork** le dÃ©pÃ´t
2. **CrÃ©ez une branche** (`git checkout -b feature/AmazingFeature`)
3. **Commit** vos changements (`git commit -m 'Add some AmazingFeature'`)
4. **Push** vers la branche (`git push origin feature/AmazingFeature`)
5. **Ouvrez une Pull Request**

---

## ğŸ“ Licence

Ce projet est sous licence **MIT** - voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ‘¨â€ğŸ’» Auteur

**Ayman**
- ï¿½ GitHub : [@aymen-cell](https://github.com/aymen-cell)
- ğŸš€ Application dÃ©ployÃ©e : [https://chatbot-aymaan.streamlit.app/](https://chatbot-aymaan.streamlit.app/)

---

## ğŸ™ Remerciements

- **Cerebras** pour leur API LLM puissante et abordable
- **LangChain** pour l'orchestration RAG
- **Streamlit** pour un framework web simplifiÃ©
- **HuggingFace** pour les modÃ¨les d'embeddings

---

## ğŸ“š Ressources utiles

- [Documentation Cerebras](https://docs.cerebras.ai/)
- [Documentation LangChain](https://python.langchain.com/)
- [Documentation Streamlit](https://docs.streamlit.io/)
- [FAISS Documentation](https://github.com/facebookresearch/faiss)

---

## ğŸ“ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifiez la section **DÃ©pannage**
2. Ouvrez une **Issue** sur GitHub
3. Contactez l'auteur directement

---

**DerniÃ¨re mise Ã  jour** : 13 fÃ©vrier 2026
**Version** : 1.0.0

